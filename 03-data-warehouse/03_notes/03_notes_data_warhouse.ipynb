{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Warehouse\n",
    "A data warehouse is an OLAP database used specifically for reporting and data analytics. It usually consists of:\n",
    "* Meta data: \n",
    "* Raw data:\n",
    "* Summary data:\n",
    "\n",
    "Data from many different sources (operational systems, other databases, APIs, flat files) are first loaded into a staging area and then loaded into the data warehouse. The data warehouse can then either output the data to **data marts** (smaller, more specialized data warehouses for specific company departments for example) or directly to end-users (analysts, reports, or machine learning models).\n",
    "\n",
    "* OLAP vs. OLTP\n",
    "* BigQuery\n",
    "    - Cost\n",
    "    - Partitions and Clustering\n",
    "    - Best Practices\n",
    "    - Internals\n",
    "    - Machine Learning in BigQuery\n",
    "\n",
    "## OLAP vs. OLTP\n",
    "There are generally two types of database systems that serve different business purposes:\n",
    "* **Online Transaction Processing (OLTP)** type databases control and run business operations in real time. They offer a view of day-to-day business transactions. They are designed for fast data updates and are usually *normalized* for efficiency. Regular backups are required to ensure business continuity and to satisfy legal and governance requirements. \n",
    "\n",
    "* **Online Analytical Processing (OLAP)** type databases support business planning, decision making, and analystics. They present a multi-dimensional view of business data. Data is periodically refreshed with scheduled, long-running batch jobs and tables are usually *denormalized* to support more efficient analytical queries. Lost data can be reloaded from OLTP databases and other sources in lieu of regular backups.\n",
    "\n",
    "## Google BigQuery\n",
    "BigQuery is a serverless data warehouse; from the perspective of the data engineer, there are no servers to manage or database software to install. The advantages of BigQuery are its scalability and high-availability:\n",
    "* It has built-in features for machine learning, geospatial analysis, and business intelligence queries.\n",
    "* It maximizes flexibility by separating the compute engine that runs queries from how it stores the data.\n",
    "\n",
    "A few notes on BigQuery:\n",
    "* BigQuery generally caches query results for improved performance. To turn this off, uncheck `⚙ More` > `Query Settings` > `☑ Use cached results`.\n",
    "* BigQuery also provides several open source public datasets for exploration.\n",
    "\n",
    "### BigQuery Cost\n",
    "Understanding service costs, especially when using cloud services, is hugely important to data engineering. BigQuery pricing has two main components:\n",
    "* **Compute pricing**: the cost to process queries. Compute pricing offer two pricing models:\n",
    "    - On-Demand pricing (per TiB): The first 1TiB of query data processed per month is free, then $6.25 for each additional TiB (up to date pricing is available on BigQuery's [pricing page](https://cloud.google.com/bigquery/pricing).)\n",
    "    - Capacity pricing (per slot-hour): Compute is charged by capacity measured in \"slots\" (virtual CPUs). You can use the BigQuery autoscaler or pre-purchase slot commitments, which are dedicated capacity that is always availabe for your workloads, at a lower price (up to date pricing is available on BigQuery's [pricing page](https://cloud.google.com/bigquery/pricing).). \n",
    "* Storage pricing: the cost to store data that is loaded into BigQuery. You pay for *active* storage and *long-term* storage.\n",
    "    - Active storage includes any table or table partition that has been modified in the last 90 days.\n",
    "    - Long-term storage includes any table or table parition that has not been modified in the last 90 days.\n",
    "\n",
    "BigQuery pricing is often subject to change, so it's advised to always keep up to date on the latest pricing for your needs.\n",
    "\n",
    "### External Tables\n",
    "BigQuery allows you to create **external tables** from data that is not directly loaded into BigQuery such as Google Cloud Storage buckets, Google Cloud SQL database, or other cloud services. However note that BigQuery cannot determine the size or number of rows of external tables because the data itself is not within BiqQuery.\n",
    "\n",
    "```SQL\n",
    "-- Creating external table referring to gcs path\n",
    "CREATE OR REPLACE EXTERNAL TABLE `taxi-rides-ny.nytaxi.external_yellow_tripdata`\n",
    "OPTIONS (\n",
    "  format = 'CSV',\n",
    "  uris = ['gs://nyc-tl-data/trip data/yellow_tripdata_2019-*.csv', 'gs://nyc-tl-data/trip data/yellow_tripdata_2020-*.csv']\n",
    ");\n",
    "```\n",
    "\n",
    "### Partitioning in BigQuery\n",
    "Partitioning tables can improve query performance and compute cost depending on the characteristics of the queries and the partitioned dimension. You can partition tables based on:\n",
    "* Time-unit column or time period\n",
    "* Ingestion time (_PARTITIONTIME)\n",
    "* Integer range\n",
    "The max number of partitions allowed in BigQuery is 4,000. See the [docs](https://cloud.google.com/bigquery/docs/partitioned-tables).\n",
    "\n",
    "To partition a table from an external table:\n",
    "```SQL\n",
    "-- Create a partitioned table from external table\n",
    "CREATE OR REPLACE TABLE taxi-rides-ny.nytaxi.yellow_tripdata_partitoned\n",
    "PARTITION BY\n",
    "  DATE(tpep_pickup_datetime) AS\n",
    "SELECT * FROM taxi-rides-ny.nytaxi.external_yellow_tripdata;\n",
    "```\n",
    "\n",
    "This might take some time as when data is partitioned from external tables, the data needs to be loaded from the external tables into BigQuery.\n",
    "\n",
    "We can also query individual partitions:\n",
    "```SQL\n",
    "-- Let's look into the partitons\n",
    "SELECT table_name, partition_id, total_rows\n",
    "FROM `nytaxi.INFORMATION_SCHEMA.PARTITIONS`\n",
    "WHERE table_name = 'yellow_tripdata_partitoned'\n",
    "ORDER BY total_rows DESC;\n",
    "```\n",
    "\n",
    "### Clustering in BigQuery\n",
    "Clustering data can also improve performance and cost. Clustering is best done on dimensions with high cardinality (columns with relatively few unique values such as product type, market regions, pickups stations, etc.) The order of the columns is important as it determines the sort order of the data. Clustering can improve filter queries and aggregate queries. The max number of clustered columns is 4 in BigQuery. BigQuery will automatically recluster tables in the background to restore proper sort order at no extra cost.\n",
    "\n",
    "To create a partitioned and clustered table:\n",
    "```SQL\n",
    "-- Creating a partition and cluster table\n",
    "CREATE OR REPLACE TABLE taxi-rides-ny.nytaxi.yellow_tripdata_partitoned_clustered\n",
    "PARTITION BY DATE(tpep_pickup_datetime)\n",
    "CLUSTER BY VendorID AS\n",
    "SELECT * FROM taxi-rides-ny.nytaxi.external_yellow_tripdata;\n",
    "```\n",
    "\n",
    "Compare the performance and cost of querying an external table vs a partitioned table vs a partitioned and clusted table:\n",
    "```SQL\n",
    "-- Create a non partitioned table from external table\n",
    "CREATE OR REPLACE TABLE taxi-rides-ny.nytaxi.yellow_tripdata_non_partitoned AS\n",
    "SELECT * FROM taxi-rides-ny.nytaxi.external_yellow_tripdata;\n",
    "\n",
    "-- Impact of partition\n",
    "-- Scanning 1.6GB of data\n",
    "SELECT DISTINCT(VendorID)\n",
    "FROM taxi-rides-ny.nytaxi.yellow_tripdata_non_partitoned\n",
    "WHERE DATE(tpep_pickup_datetime) BETWEEN '2019-06-01' AND '2019-06-30';\n",
    "\n",
    "-- Scanning ~106 MB of DATA\n",
    "SELECT DISTINCT(VendorID)\n",
    "FROM taxi-rides-ny.nytaxi.yellow_tripdata_partitoned\n",
    "WHERE DATE(tpep_pickup_datetime) BETWEEN '2019-06-01' AND '2019-06-30';\n",
    "\n",
    "-- Impact of partition and cluster\n",
    "-- Query scans 1.1 GB\n",
    "SELECT count(*) as trips\n",
    "FROM taxi-rides-ny.nytaxi.yellow_tripdata_partitoned\n",
    "WHERE DATE(tpep_pickup_datetime) BETWEEN '2019-06-01' AND '2020-12-31'\n",
    "  AND VendorID=1;\n",
    "\n",
    "-- Query scans 864.5 MB\n",
    "SELECT count(*) as trips\n",
    "FROM taxi-rides-ny.nytaxi.yellow_tripdata_partitoned_clustered\n",
    "WHERE DATE(tpep_pickup_datetime) BETWEEN '2019-06-01' AND '2020-12-31'\n",
    "  AND VendorID=1;\n",
    "```\n",
    "\n",
    "Note: Tables with data of less than 1GiB in size don't show significant improvement with partitioning and clustering.\n",
    "\n",
    "## BigQuery Best Practices\n",
    "For cost reduction:\n",
    "* Avoid `select *` to reduce amount of data returned (more compute).\n",
    "* Price queries before running them.\n",
    "* Use clustered or partitioned tables.\n",
    "* Be careful with streaming inserts\n",
    "* Materialize query results in stages.\n",
    "\n",
    "For query performance:\n",
    "* Filter on partitioned columns.\n",
    "* Denormalize the data.\n",
    "* Use nested or repeated columns (when denormalizing data).\n",
    "* Use external data sources sparingly.\n",
    "* Reduce data before using a `JOIN` operation.\n",
    "* Do not treat `WITH` clauses as prepared statements.\n",
    "* Avoid oversharding tables (don't split them up too much).\n",
    "* Avoid JavaScript user-defined functions.\n",
    "* Use approximate aggregation functions.\n",
    "* Use `ORDER BY` last.\n",
    "* Optimize join patterns.\n",
    "* Place the table with the largest number of rows first, followed by the table with the fewest rows, and then the remaining tables by decreasing row size. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
