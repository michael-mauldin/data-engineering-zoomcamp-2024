{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Analytics Engineering?\n",
    "- The **analytics** engineer role sites between a data engineer, who prepares and maintains the data infrastructure and the data analyst, who is using data to answer business questions and solve problems.\n",
    "- The analytics engineer introduces good software engineering practices to the efforts of data analysts and data engineers.\n",
    "\n",
    "Remember the tradition data process looks something like this:\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    A[Data loading] --> B[Data storing]\n",
    "    B[Data storing] --> C[Data modeling]\n",
    "    C[Data modeling] --> D[Data presentation]\n",
    "```\n",
    "\n",
    "Analytics engineers are often focused on the data modeling and data presentation steps. But what does it mean to \"model\" data? Today there are several popular approaches to modeling data and building data warehouses.\n",
    "\n",
    "1. Kimball Dimensional Modeling (Star Schema)\n",
    "- Ralph Kimball is a prominent figure in the field of data warehousing and business intelligence. He pioneered dimensional modeling and wrote the book \"The Data Warehouse Toolkit\", an essential reference for creating and maintaining data warehouses.\n",
    "- Kimball focuses on building simple, practical, and accessible data warehouses, optimized for query performance and ease of use by end users. It employs a bottom-up approach, where smaller, subject-specific data marts are built first and then integrated into a larger enterprise data warehouse.\n",
    "- The data model relies on a **star schema** design, where data is organized into facts (measureable, quantitative data) and related dimensions (descriptive attributes).\n",
    "- Kimball allows data denormalization where needed, which can lead to data redundancy but enables simplified querying and improved performance.\n",
    "- It emphasizes iterative development and delivering business value in smaller increments.\n",
    "\n",
    "2. Inmon Methodology\n",
    "- Bill Inmon is another prominent figure in the field of data warehousing and business intelligence, often called the \"father of data warehousing\". He coined the term \"data warehouse\" and wrote several influential books, including \"Building the Data Warehouse\".\n",
    "- Inmon prioritizes data integration and consistency across an organization. It employes a top-down approach, where the enterprise data warehouse is built first as a centralized repository for all organizational data and then data marts are created from this source as needed.\n",
    "- Inmon emphasizes normalizing data in third normal form (3NF) to reduce data redundancy and ensure data integrity.\n",
    "- This approach allows data warehouses and data models to be more scalable and adaptable to changing business needs due to its centralized nature.\n",
    "- However this approach is usually more complex and time-consuming to implement when compared to Kimball's approach.\n",
    "\n",
    "3. Data Vault\n",
    "- Data Vault was created by Dan Linstedt in the late 1990s as a reaction to real world challenges he encountered while working on large data warehouse projects. His book \"Building a Scalable Data Warehouse with Data Vault 2.0\" describes the data vault approach.\n",
    "- A data vault is set up in a hub-and-spoke architecture, with three core components: hubs (containing business keys), links (joining keys between hubs), and satellites (containing descriptive attributes).\n",
    "- This approach excels in capturing historical data changes and providing a detailed audit trail for data.\n",
    "- Its highly adaptable to changing business needs and is highly scalable due to its modular design.\n",
    "- However data vault modeling can be complex to understand and implement, especially for business users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elements of dimensional modeling\n",
    "In this course we will use the dimensional modeling approach. Dimensional modeling includes fact tables and dimension tables.\n",
    "\n",
    "* Fact tables\n",
    "    - Record measurements, metrics, or facts that correspond to a business process. Ex. \"verbs\" like sales, orders, transactions.\n",
    " * Dimension tables\n",
    "    - Corresponds to business entities that provide context to a business process. Ex. \"nouns\" like customer, product, regions.\n",
    "\n",
    "The architecture containing a dimensional model is usually composed of a staging area, a processing area, and a presentation area:\n",
    "\n",
    "```mermaid\n",
    "flowchart TB\n",
    "    A[\"Stage Area (raw data)\"] --> B[\"Processing Area (data models)\"]\n",
    "    B[\"Processing Area (data models)\"] --> C[\"Presentation Area (reports, dashboards)\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data modeling with dbt\n",
    "**dbt** (**d**ata **b**uild **t**ool) is a transformation workflow tool that modularizes SQL code into discrete units called **models**. These models represent individual transformations or business logic applied to the data.\n",
    "\n",
    "Models are written using SQL within Jinja templates and are then compiled into `*.sql` files.\n",
    "\n",
    "dbt provides several other tools for:\n",
    "- Dependency management: users can define dependencies between models to ensure they are executed in the correct order\n",
    "- Version control: dbt integrates with version control systems like git, allowing data transformations and business logic to be tracked across time.\n",
    "- Testing: it includes a testing framework to enable users to test their data models.\n",
    "\n",
    "dbt usually sits on top of a data warehouse, processing data as its ingested as well as throughout the warehouse.\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    c[Data loaders] --> a\n",
    "    subgraph s1 [dbt]\n",
    "        subgraph ss1 [Data warehouse]\n",
    "            a[Raw data] --> b[Transformed data]\n",
    "        end\n",
    "    end\n",
    "    b --> d[BI Tools]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to use dbt:\n",
    "1. dbt Core\n",
    "    - dbt Core is an open-source command line tool used to set up, build, and run dbt projects (which are made up of `.sql` and `.yml` files).\n",
    "    - --> [Installation instructions](https://docs.getdbt.com/docs/core/installation-overview)\n",
    "\n",
    "2. dbt Cloud\n",
    "    - [dbt Cloud](https://cloud.getdbt.com/) is a web-based IDE application used to develop, test, and run dbt projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
